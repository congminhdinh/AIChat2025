@startuml system_architecture_container
'*****************************************************
' AIChat2025 - Container Diagram (C4 Level 2)
' Purpose: Show microservices and infrastructure
' Chapter: Chapter 4 - Design & Implementation
'*****************************************************

!include https://raw.githubusercontent.com/plantuml-stdlib/C4-PlantUML/master/C4_Container.puml

LAYOUT_TOP_DOWN()
'LAYOUT_WITH_LEGEND()

title Container Diagram - AIChat2025 Microservices Architecture

Person(user, "User", "Employee or Admin")

System_Boundary(c1, "AIChat2025 System") {
    Container(webapp, "WebApp", "ASP.NET MVC 9", "Provides web UI:\n- Login/Register\n- Chat interface\n- Document management")

    Container(gateway, "API Gateway", "YARP 2.3.0", "Routes requests to microservices:\n- Load balancing\n- Authentication forwarding")

    Container(account, "AccountService", ".NET 9 Minimal API", "Handles:\n- Authentication (JWT)\n- User management\n- Password hashing (BCrypt)")

    Container(tenant, "TenantService", ".NET 9 Minimal API", "Handles:\n- Tenant management\n- Multi-tenant configuration")

    Container(document, "DocumentService", ".NET 9 Minimal API", "Handles:\n- Document upload\n- Background vectorization (Hangfire)\n- .docx parsing")

    Container(storage, "StorageService", ".NET 9 Minimal API", "Handles:\n- File upload to MinIO\n- File download\n- S3-compatible storage")

    Container(chat, "ChatService", ".NET 9 + SignalR", "Handles:\n- SignalR WebSocket hub\n- Chat orchestration\n- RabbitMQ integration")

    Container(embedding, "EmbeddingService", "Python FastAPI", "Handles:\n- Text embedding (768-dim)\n- Qdrant integration\n- Batch vectorization")

    Container(chatprocessor, "ChatProcessor", "Python FastAPI", "Handles:\n- RAG pipeline (9 steps)\n- Dual-RAG search\n- LLM generation (Ollama)")

    ContainerDb(db, "SQL Server", "SQL Server 2022", "Stores:\n- Accounts, Tenants\n- Conversations, Messages\n- Documents, Configs")

    ContainerDb(vector, "Qdrant", "Vector Database", "Stores:\n- 768-dim vectors\n- Metadata (document_name, headings)\n- COSINE similarity search")

    Container(queue, "RabbitMQ", "Message Queue", "Handles:\n- UserPromptReceivedEvent\n- BotResponseCreatedEvent\n- Async messaging")

    ContainerDb(minio, "MinIO", "Object Storage", "Stores:\n- .docx files\n- S3-compatible")

    Container(ollama, "Ollama", "LLM Server", "Hosts:\n- ontocord/vistral:latest\n- Vietnamese-finetuned LLM")
}

Rel(user, webapp, "Uses", "HTTPS")
Rel(webapp, gateway, "API calls", "HTTPS")

Rel(gateway, account, "Routes", "HTTP")
Rel(gateway, tenant, "Routes", "HTTP")
Rel(gateway, document, "Routes", "HTTP")
Rel(gateway, storage, "Routes", "HTTP")
Rel(gateway, chat, "Routes", "HTTP/WebSocket")

Rel(webapp, chat, "WebSocket", "SignalR")

Rel(account, db, "Reads/Writes", "SQL")
Rel(tenant, db, "Reads/Writes", "SQL")
Rel(document, db, "Reads/Writes", "SQL")
Rel(chat, db, "Reads/Writes", "SQL")

Rel(storage, minio, "Uploads/Downloads", "S3 API")
Rel(document, storage, "File operations", "HTTP API")

Rel(document, embedding, "Vectorize batch", "HTTP API")
Rel(embedding, vector, "Store/Search vectors", "gRPC/HTTP")

Rel(chat, queue, "Publish events", "AMQP")
Rel(chatprocessor, queue, "Consume/Publish", "AMQP")

Rel(chatprocessor, vector, "Vector search", "HTTP")
Rel(chatprocessor, ollama, "LLM generation", "HTTP")

Rel(queue, chat, "Bot response", "AMQP")

note right of chatprocessor
  **RAG Pipeline:**
  1. Embed query
  2. Dual search (company + legal)
  3. Determine scenario
  4. Structure context
  5. Build prompt
  6. LLM generate
  7. Cleanup response
  8. Publish response
  9. Log RAGAS metrics
end note

note as N1
  **Technology Stack:**
  - Backend: .NET 9 (7 services)
  - AI Workers: Python 3.11+ (2 services)
  - Database: SQL Server 2022
  - Vector DB: Qdrant
  - Message Queue: RabbitMQ 3
  - Storage: MinIO
  - LLM: Ollama + Vistral
  - Deployment: Docker Compose (13 containers)
end note

@enduml
