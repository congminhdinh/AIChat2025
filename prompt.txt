Act as a Senior Python AI Developer.

**Task:** Update the `ChatProcessor` logic to enforce concise AI responses.

**Scope:**
* **Target:** ONLY modify the function responsible for constructing the final prompt string sent to Ollama (likely inside `business.py` or `services/llm_service.py`).
* **Strict Constraint:** Do NOT modify the RabbitMQ consumer, Qdrant search logic, configuration loading, or logger setup. Preserve the existing RAG flow (Context retrieval) exactly as it is.

**Action:**
1.  Locate the code where `system_instruction`, `context` (from Qdrant), and `user_message` are combined.
2.  Inject the following specific instruction into the final prompt to the model:
    > **"IMPORTANT: Answer based on the context provided. Keep the answer concise, roughly 2-3 sentences only."**
3.  Ensure the retrieved `context` is still included in the prompt.

**Output:**
Provide ONLY the modified Python function code.