Refactor ChatProcessor: Model Update & Async Batch Testing

Update Model Configuration:

In ChatProcessor (or Ollama config), change the model to ontocord/vistral:latest.

Create/Update Endpoint: POST /api/test/batch

Input Body: A list of { tenant_id, TC_id, questions }.

Response Behavior: Return an immediate HTTP 200 OK (or 202 Accepted) to the client. Do not wait for the processing to finish. Do not return the results in the HTTP response.

Background Processing Logic:

Upon receiving the request, spawn a background task (e.g., using Task.Run or a background worker).

Inside this background task:

Iterate through the input list.

For each entity:

Call the existing core chat logic (reuse the Service method used by RabbitMQ).

Delay: Wait 3 seconds (await Task.Delay(3000)) after each entity.

Collect the result ({ TC_id, answer }) into a generic list.

File Output: Once the loop is complete, serialize the final list of results to JSON and save it to a file named tdd.json in the root (or output) directory.